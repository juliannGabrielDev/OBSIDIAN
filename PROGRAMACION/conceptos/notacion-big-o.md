---
aliases:
  - Notaci√≥n Big O üöÄ
tags:
  - conceptos
breadcrumb:
  - "[[indice-web|üßë‚Äçüíª Programaci√≥n üíª‚ú®]]"
Fecha: 2025-06-03
---
# Notaci√≥n Big O üöÄ

## 1. ¬øQu√© es la Notaci√≥n Big O? ü§î

La **Notaci√≥n Big O** es una forma matem√°tica de describir el **l√≠mite superior** del tiempo de ejecuci√≥n o el espacio de memoria que un algoritmo utilizar√° en el peor de los casos, a medida que el tama√±o de la entrada (input) tiende a infinito. En palabras m√°s sencillas, nos dice c√≥mo se **escala** un algoritmo.
- Nos ayuda a entender c√≥mo el **rendimiento** de un algoritmo cambia a medida que la cantidad de datos de entrada aumenta.
- Se enfoca en el <mark style="background: #FFB8EBA6;">**peor escenario**</mark> (worst-case scenario), lo que nos da una garant√≠a de rendimiento.
- Ignora constantes y t√©rminos de menor orden, porque lo que realmente importa es la **tasa de crecimiento** a medida que la entrada se vuelve muy grande. Por ejemplo, si un algoritmo tarda `5n^2 + 3n + 20` operaciones, su Big O es `O(n^2)`.
## 2. ¬øPor qu√© es Importante? üí°
Entender la Notaci√≥n Big O es crucial porque:
- Permite **comparar** la eficiencia de diferentes algoritmos que resuelven el mismo problema.
- Ayuda a **predecir** c√≥mo se comportar√° un algoritmo con grandes cantidades de datos.
- Es fundamental para escribir c√≥digo **eficiente** y **escalable**, especialmente en aplicaciones grandes.
- Facilita la toma de decisiones sobre qu√© estructura de datos o algoritmo elegir para una tarea espec√≠fica. <mark style="background: #BBFABBA6;">¬°Elegir bien puede hacer una gran diferencia!</mark>
## 3. Complejidades Comunes y Ejemplos üìä
Aqu√≠ te presento una tabla con las complejidades m√°s comunes, de la m√°s eficiente a la menos eficiente, junto con ejemplos sencillos:

| **Big O**            | **Nombre**      | **Descripci√≥n**                                                                      | **Ejemplo Sencillo (conceptual)**                                                                                                                                                                                                                        |
| -------------------- | --------------- | ------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **O(1)**             | **Constante**   | El tiempo de ejecuci√≥n es el mismo, sin importar el tama√±o de la entrada.            | Acceder a un elemento de un array por su √≠ndice: `array[5]`.                                                                                                                                                                                             |
| **O(log n)**         | **Logar√≠tmica** | El tiempo de ejecuci√≥n crece logar√≠tmicamente con el tama√±o de la entrada.           | B√∫squeda binaria en un array ordenado. <mark style="background: #FFF3A3A6;">¬°Muy eficiente para b√∫squedas!</mark>                                                                                                                                        |
| **O(n)**             | **Lineal**      | El tiempo de ejecuci√≥n crece linealmente con el tama√±o de la entrada.                | Recorrer todos los elementos de un array una vez: `for item in array: print(item)`.                                                                                                                                                                      |
| **O(n log n)**       | **Log-Lineal**  | Una combinaci√≥n com√∫n, a menudo vista en algoritmos de ordenamiento eficientes.      | Algoritmos de ordenamiento como Merge Sort o Quick Sort (en su caso promedio y mejor).                                                                                                                                                                   |
| **O(n<sup>2</sup>)** | **Cuadr√°tica**  | El tiempo de ejecuci√≥n crece proporcionalmente al cuadrado del tama√±o de la entrada. | Bucles anidados que iteran sobre la misma colecci√≥n: `for i in array: for j in array: ...`.                                                                                                                                                              |
| **O(2<sup>n</sup>)** | **Exponencial** | El tiempo de ejecuci√≥n se duplica con cada elemento adicional en la entrada.         | Algunos algoritmos recursivos que resuelven un problema de tama√±o `n` haciendo dos llamadas recursivas de tama√±o `n-1`, como el c√°lculo de Fibonacci de forma recursiva simple. <mark style="background: #FF5582A6;">¬°Se vuelve lento muy r√°pido!</mark> |
| **O(n!)**            | **Factorial**   | El tiempo de ejecuci√≥n crece de forma factorial.                                     | Generar todas las permutaciones posibles de una lista. El problema del viajante (TSP) resuelto por fuerza bruta.                                                                                                                                         |
**Ilustraci√≥n Conceptual del Crecimiento:**
Imagina que `n` es el n√∫mero de elementos:
- **O(1):** Siempre toma el mismo tiempo, no importa si son 10 o 1 mill√≥n de elementos.
- **O(log n):** Si tienes 1000 elementos, podr√≠a tomar, digamos, 10 pasos. Si duplicas a 2000, solo toma 11 pasos. ¬°Crece muy lento!
- **O(n):** Si tienes 1000 elementos, toma 1000 "unidades de tiempo". Si duplicas a 2000, toma 2000 "unidades de tiempo".
- **O(n<sup>2</sup>):** Si tienes 10 elementos, toma 100 "unidades de tiempo". Si tienes 100 elementos, ¬°toma 10,000! <mark style="background: #FFB86CA6;">Crece r√°pido.</mark>
- **O(2<sup>n</sup>):** Si tienes 10 elementos, toma 1024 "unidades de tiempo". Si tienes 20, ¬°toma m√°s de un mill√≥n!
## 4. Reglas Generales para Calcular Big O ‚úçÔ∏è
Cuando analizas un algoritmo, puedes seguir estas reglas:
1. **Peor Caso:** Siempre considera el escenario que tomar√≠a m√°s tiempo.
2. **Eliminar Constantes:** Si un algoritmo realiza `2n` operaciones, su Big O es `O(n)`, no `O(2n)`. Las constantes no importan a gran escala.
    - _Ejemplo:_ `O(500)` es `O(1)`. `O(13n^2)` es `O(n^2)`.
3. **T√©rminos No Dominantes:** Si un algoritmo tiene operaciones `n^2 + n`, el t√©rmino `n` es mucho menos significativo que `n^2` para valores grandes de `n`. As√≠ que el Big O es `O(n^2)`. <mark style="background: #ADCCFFA6;">Nos quedamos con el t√©rmino que crece m√°s r√°pido.</mark>
    - _Ejemplo:_ `O(n^3 + 50n^2 + 10000)` es `O(n^3)`.
4. **Operaciones Secuenciales (una despu√©s de otra):** Se suman las complejidades.
    - _Ejemplo:_ Un bloque de c√≥digo `O(n)` seguido de un bloque `O(log n)` es `O(n + log n)`. Seg√∫n la regla 3, esto se simplifica a `O(n)`.
5. **Operaciones Anidadas (un bucle dentro de otro):** Se multiplican las complejidades.
    - _Ejemplo:_ Un bucle externo que corre `n` veces y un bucle interno que corre `m` veces para cada iteraci√≥n del externo, resulta en `O(n*m)`. Si ambos corren `n` veces, es `O(n*n) = O(n^2)`.
**Ejemplo Pr√°ctico de An√°lisis:**
```python
def ejemplo_funcion(lista):
  print(lista[0]) # O(1)

  for elemento in lista: # O(n) - Bucle 1
    print(elemento)

  for elemento in lista: # O(n) - Bucle 2 (secuencial)
    for otro_elemento in lista: # O(n) - Bucle 3 (anidado dentro del 2)
      print(elemento, otro_elemento)
```
An√°lisis:
- La primera l√≠nea es **O(1)**.
- El primer bucle `for` es **O(n)**.
- El segundo bloque de bucles anidados: el externo es `O(n)` y el interno es `O(n)`, entonces juntos son `O(n*n) = O(n^2)`.
Sumando las complejidades (secuencial): O(1) + O(n) + O(n^2).
Aplicando la regla de t√©rminos no dominantes, nos quedamos con el m√°s grande: <mark style="background: #D2B3FFA6;">O(n<sup>2</sup>)</mark>.
## 5. Mini Repaso Final ‚ú®
- **Notaci√≥n Big O** describe la <mark style="background: #ABF7F7A6;">**eficiencia**</mark> (tiempo o espacio) de un algoritmo en el peor de los casos.
- Se enfoca en c√≥mo el rendimiento **escala** con el aumento del tama√±o de la entrada (`n`).
- Ignora constantes y t√©rminos menos significativos.
- Complejidades comunes incluyen **O(1)** (genial üëç), **O(log n)**, **O(n)**, **O(n log n)**, **O(n<sup>2</sup>)**, y **O(2<sup>n</sup>)** (peligroso para entradas grandes üëé).
- Conocer Big O te ayuda a escribir c√≥digo m√°s **r√°pido** y **escalable**.